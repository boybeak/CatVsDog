{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some final variables\n",
    "imageSize = 224\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def readImage(path):\n",
    "    img = image.load_img(path, target_size=(imageSize, imageSize))\n",
    "    x = image.img_to_array(img)\n",
    "    x = x.astype('float32')\n",
    "    x /= 255.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabel(path):\n",
    "    name = path[path.rfind('/') + 1:path.index('.')]\n",
    "#     print (name)\n",
    "    return 1 if name == 'dog' else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "def getPreds(img_path):\n",
    "    img = image.load_img(img_path, target_size=(imageSize, imageSize))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    preds = model.predict(x)\n",
    "    result = decode_predictions(preds, top=50)[0]\n",
    "#     print('Predicted:', result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs = [\n",
    " 'n02085620','n02085782','n02085936','n02086079'\n",
    ",'n02086240','n02086646','n02086910','n02087046'\n",
    ",'n02087394','n02088094','n02088238','n02088364'\n",
    ",'n02088466','n02088632','n02089078','n02089867'\n",
    ",'n02089973','n02090379','n02090622','n02090721'\n",
    ",'n02091032','n02091134','n02091244','n02091467'\n",
    ",'n02091635','n02091831','n02092002','n02092339'\n",
    ",'n02093256','n02093428','n02093647','n02093754'\n",
    ",'n02093859','n02093991','n02094114','n02094258'\n",
    ",'n02094433','n02095314','n02095570','n02095889'\n",
    ",'n02096051','n02096177','n02096294','n02096437'\n",
    ",'n02096585','n02097047','n02097130','n02097209'\n",
    ",'n02097298','n02097474','n02097658','n02098105'\n",
    ",'n02098286','n02098413','n02099267','n02099429'\n",
    ",'n02099601','n02099712','n02099849','n02100236'\n",
    ",'n02100583','n02100735','n02100877','n02101006'\n",
    ",'n02101388','n02101556','n02102040','n02102177'\n",
    ",'n02102318','n02102480','n02102973','n02104029'\n",
    ",'n02104365','n02105056','n02105162','n02105251'\n",
    ",'n02105412','n02105505','n02105641','n02105855'\n",
    ",'n02106030','n02106166','n02106382','n02106550'\n",
    ",'n02106662','n02107142','n02107312','n02107574'\n",
    ",'n02107683','n02107908','n02108000','n02108089'\n",
    ",'n02108422','n02108551','n02108915','n02109047'\n",
    ",'n02109525','n02109961','n02110063','n02110185'\n",
    ",'n02110341','n02110627','n02110806','n02110958'\n",
    ",'n02111129','n02111277','n02111500','n02111889'\n",
    ",'n02112018','n02112137','n02112350','n02112706'\n",
    ",'n02113023','n02113186','n02113624','n02113712'\n",
    ",'n02113799','n02113978']\n",
    "\n",
    "cats=[\n",
    "'n02123045','n02123159','n02123394','n02123597'\n",
    ",'n02124075','n02125311','n02127052']\n",
    "\n",
    "def isCat(preds):\n",
    "    for item in preds:\n",
    "        if item[0] in cats:\n",
    "            return True\n",
    "    return False\n",
    "def isDog(preds):\n",
    "    for item in preds:\n",
    "        if item[0] in dogs:\n",
    "            return True\n",
    "    return False\n",
    "def isValid(img_path):\n",
    "    label = getLabel(img_path)\n",
    "    preds = getPreds(img_path)\n",
    "    return {\n",
    "        0:isCat(preds),\n",
    "        1:isDog(preds)\n",
    "    }[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 need to preprocess\n",
      "24836 files validCatVsDog/train/dog.12499.jpg\n",
      "\n",
      "164 invalid files as below:\n",
      "\r"
     ]
    }
   ],
   "source": [
    "# Preprocess pics\n",
    "import helper\n",
    "\n",
    "\n",
    "train_dir = 'train/'\n",
    "valid_files = []\n",
    "invalid_files = []\n",
    "train_files = helper.get_train_files()\n",
    "train_files = sorted(train_files, key=lambda s: (len(s), s))\n",
    "\n",
    "print(str(len(train_files)) + \" need to preprocess\")\n",
    "\n",
    "for i in range(len(train_files)):\n",
    "    file = train_files[i]\n",
    "    print (file, end='\\r')\n",
    "    if isValid(file):\n",
    "        valid_files.append(file)\n",
    "    else:\n",
    "        invalid_files.append(file)\n",
    "\n",
    "print (str(len(valid_files)) + \" files valid\\n\")\n",
    "print (str(len(invalid_files)) + \" invalid files as below:\\n\", end='\\r')\n",
    "# print (invalid_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFeatureAndLabel(valid_files):\n",
    "    file_count = len(valid_files)\n",
    "    print(\"readFeatureAndLabel file_count=\" + str(file_count))\n",
    "    train_feature = []\n",
    "    train_label = []\n",
    "    for i in range(file_count):\n",
    "        f = train_files[i]\n",
    "#         print (f)\n",
    "        train_feature.append(readImage(f))\n",
    "        train_label.append(getLabel(f))\n",
    "    \n",
    "    return train_feature, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readFeatureAndLabel file_count=24836\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "total_feature, total_label = readFeatureAndLabel(valid_files)\n",
    "total_feature = np.array(total_feature)\n",
    "\n",
    "total_label = np.array(total_label)\n",
    "\n",
    "train_feature, validation_feature, train_label, validation_label = train_test_split(total_feature, total_label, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22352 samples, validate on 2484 samples\n",
      "Epoch 1/20\n",
      "22352/22352 [==============================] - 36s 2ms/step - loss: 0.4423 - acc: 0.8348 - val_loss: 0.1046 - val_acc: 0.9710\n",
      "Epoch 2/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.2596 - acc: 0.9212 - val_loss: 0.0691 - val_acc: 0.9795\n",
      "Epoch 3/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.2090 - acc: 0.9332 - val_loss: 0.0717 - val_acc: 0.9767\n",
      "Epoch 4/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.1862 - acc: 0.9365 - val_loss: 0.0533 - val_acc: 0.9835\n",
      "Epoch 5/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.1708 - acc: 0.9401 - val_loss: 0.0545 - val_acc: 0.9827\n",
      "Epoch 6/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.1580 - acc: 0.9450 - val_loss: 0.0614 - val_acc: 0.9803\n",
      "Epoch 7/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.1511 - acc: 0.9457 - val_loss: 0.0530 - val_acc: 0.9819\n",
      "Epoch 8/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.1454 - acc: 0.9463 - val_loss: 0.0463 - val_acc: 0.9839\n",
      "Epoch 9/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.1413 - acc: 0.9473 - val_loss: 0.0506 - val_acc: 0.9815\n",
      "Epoch 10/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.1395 - acc: 0.9479 - val_loss: 0.0512 - val_acc: 0.9823\n",
      "Epoch 11/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.1340 - acc: 0.9487 - val_loss: 0.0488 - val_acc: 0.9835\n",
      "Epoch 12/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.1325 - acc: 0.9491 - val_loss: 0.0537 - val_acc: 0.9819\n",
      "Epoch 13/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.1286 - acc: 0.9520 - val_loss: 0.0465 - val_acc: 0.9827\n",
      "Epoch 14/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.1287 - acc: 0.9507 - val_loss: 0.0535 - val_acc: 0.9815\n",
      "Epoch 15/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.1256 - acc: 0.9534 - val_loss: 0.0454 - val_acc: 0.9835\n",
      "Epoch 16/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.1237 - acc: 0.9518 - val_loss: 0.0438 - val_acc: 0.9855\n",
      "Epoch 17/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.1217 - acc: 0.9529 - val_loss: 0.0481 - val_acc: 0.9827\n",
      "Epoch 18/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.1201 - acc: 0.9537 - val_loss: 0.0429 - val_acc: 0.9855\n",
      "Epoch 19/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.1197 - acc: 0.9537 - val_loss: 0.0491 - val_acc: 0.9823\n",
      "Epoch 20/20\n",
      "22352/22352 [==============================] - 32s 1ms/step - loss: 0.1181 - acc: 0.9544 - val_loss: 0.0499 - val_acc: 0.9827\n"
     ]
    }
   ],
   "source": [
    "# Plan C\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "# optimizer='rmsprop'\n",
    "# , beta_1=0.9, beta_2=0.999, epsilon=1e-08\n",
    "opt = Adam(lr=0.0002)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "history = model.fit(train_feature, train_label, batch_size=batch_size, epochs=20, validation_data=(validation_feature, validation_label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22352 samples, validate on 2484 samples\n",
      "Epoch 1/20\n",
      "22352/22352 [==============================] - 41s 2ms/step - loss: 0.0867 - acc: 0.9675 - val_loss: 0.0534 - val_acc: 0.9883\n",
      "Epoch 2/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0346 - acc: 0.9868 - val_loss: 0.0428 - val_acc: 0.9899\n",
      "Epoch 3/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0197 - acc: 0.9932 - val_loss: 0.0744 - val_acc: 0.9787\n",
      "Epoch 4/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0130 - acc: 0.9962 - val_loss: 0.0363 - val_acc: 0.9891\n",
      "Epoch 5/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0130 - acc: 0.9949 - val_loss: 0.0366 - val_acc: 0.9847\n",
      "Epoch 6/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0120 - acc: 0.9960 - val_loss: 0.0832 - val_acc: 0.9851\n",
      "Epoch 7/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0070 - acc: 0.9976 - val_loss: 0.0550 - val_acc: 0.9895\n",
      "Epoch 8/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0052 - acc: 0.9981 - val_loss: 0.0612 - val_acc: 0.9827\n",
      "Epoch 9/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0073 - acc: 0.9975 - val_loss: 0.0475 - val_acc: 0.9911\n",
      "Epoch 10/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0805 - val_acc: 0.9867\n",
      "Epoch 11/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0051 - acc: 0.9982 - val_loss: 0.0522 - val_acc: 0.9891\n",
      "Epoch 12/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0045 - acc: 0.9983 - val_loss: 0.2483 - val_acc: 0.9424\n",
      "Epoch 13/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0517 - val_acc: 0.9863\n",
      "Epoch 14/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0761 - val_acc: 0.9863\n",
      "Epoch 15/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0932 - val_acc: 0.9819\n",
      "Epoch 16/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0545 - val_acc: 0.9883\n",
      "Epoch 17/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0051 - acc: 0.9982 - val_loss: 0.0501 - val_acc: 0.9887\n",
      "Epoch 18/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0018 - acc: 0.9993 - val_loss: 0.0702 - val_acc: 0.9827\n",
      "Epoch 19/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0034 - acc: 0.9988 - val_loss: 0.0507 - val_acc: 0.9911\n",
      "Epoch 20/20\n",
      "22352/22352 [==============================] - 35s 2ms/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0968 - val_acc: 0.9831\n"
     ]
    }
   ],
   "source": [
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "# for i, layer in enumerate(base_model.layers):\n",
    "#     print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "# loss='sparse_categorical_crossentropy'\n",
    "from keras.optimizers import SGD\n",
    "# SGD(lr=0.001, momentum=0.9)\n",
    "opt2 = Adam(lr=0.001)\n",
    "model.compile(optimizer=opt2, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "history2 = model.fit(train_feature, train_label, batch_size=batch_size, epochs=20, validation_data=(validation_feature, validation_label), class_weight='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mindex_of\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m   2339\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2341\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'values'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4bbdf2c5884f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Loss Curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Validation Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3357\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3358\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3359\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1527\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mindex_of\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m   2340\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2341\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2342\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2343\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2057\u001b[0m     '''\n\u001b[1;32m   2058\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \"\"\"\n\u001b[0;32m--> 544\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAFpCAYAAAC8iwByAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAD91JREFUeJzt3F+I5Xd5x/HPY9ZUqlZLs4LkT5PStXaxBe2QWgrVoi1JLjYXtpKAtEpwwTZSqggpFpX0qi1tQUirKxXbgsa0F7LgSgo2IkgjWbEGE0nZRms2Cln/NDeiMe3TiznWcbq7c3ZzZvbZPa8XDJzfOd855+GbYd45Z377q+4OADDXsy70AADA2Yk1AAwn1gAwnFgDwHBiDQDDiTUADLdjrKvqg1X1RFV98QyPV1W9t6pOVNWDVfWK1Y8JAOtrmXfWH0pyw1kevzHJgcXX4SR/88zHAgB+YMdYd/enk3zrLEtuTvL3ven+JC+sqhevakAAWHer+Jv1lUke23J8cnEfALAC+/byxarqcDY/Ks9zn/vcX3rpS1+6ly8PABfM5z73uW909/7z+d5VxPrxJFdvOb5qcd//091HkhxJko2NjT5+/PgKXh4A5quq/zzf713Fx+BHk/zO4qzwVyZ5sru/voLnBQCyxDvrqvpIklcnuaKqTiZ5d5JnJ0l3vy/JsSQ3JTmR5DtJ3rRbwwLAOtox1t196w6Pd5LfX9lEAMCPcAUzABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIZbKtZVdUNVPVJVJ6rqjtM8fk1V3VdVn6+qB6vqptWPCgDracdYV9VlSe5KcmOSg0luraqD25b9cZJ7uvvlSW5J8terHhQA1tUy76yvT3Kiux/t7qeS3J3k5m1rOslPLG6/IMnXVjciAKy3fUusuTLJY1uOTyb55W1r3pPkn6vqrUmem+S1K5kOAFjZCWa3JvlQd1+V5KYk/1BV/++5q+pwVR2vquOnTp1a0UsDwKVtmVg/nuTqLcdXLe7b6rYk9yRJd/9rkuckuWL7E3X3ke7e6O6N/fv3n9/EALBmlon1A0kOVNV1VXV5Nk8gO7ptzVeTvCZJqurnsxlrb50BYAV2jHV3P53k9iT3JvlSNs/6fqiq7qyqQ4tlb0/y5qr6QpKPJHljd/duDQ0A62SZE8zS3ceSHNt237u23H44ya+udjQAIHEFMwAYT6wBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGG6pWFfVDVX1SFWdqKo7zrDm9VX1cFU9VFUfXu2YALC+9u20oKouS3JXkt9IcjLJA1V1tLsf3rLmQJI/SvKr3f3tqnrRbg0MAOtmmXfW1yc50d2PdvdTSe5OcvO2NW9Ocld3fztJuvuJ1Y4JAOtrmVhfmeSxLccnF/dt9ZIkL6mqz1TV/VV1w+meqKoOV9Xxqjp+6tSp85sYANbMqk4w25fkQJJXJ7k1yQeq6oXbF3X3ke7e6O6N/fv3r+ilAeDStkysH09y9Zbjqxb3bXUyydHu/n53fznJv2cz3gDAM7RMrB9IcqCqrquqy5PckuTotjUfy+a76lTVFdn8WPzRFc4JAGtrx1h399NJbk9yb5IvJbmnux+qqjur6tBi2b1JvllVDye5L8k7uvubuzU0AKyT6u4L8sIbGxt9/PjxC/LaALDXqupz3b1xPt/rCmYAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADLdUrKvqhqp6pKpOVNUdZ1n3uqrqqtpY3YgAsN52jHVVXZbkriQ3JjmY5NaqOniadc9P8gdJPrvqIQFgnS3zzvr6JCe6+9HufirJ3UluPs26P0nyp0m+u8L5AGDtLRPrK5M8tuX45OK+/1NVr0hydXd//GxPVFWHq+p4VR0/derUOQ8LAOvoGZ9gVlXPSvKXSd6+09ruPtLdG929sX///mf60gCwFpaJ9eNJrt5yfNXivh94fpKXJflUVX0lySuTHHWSGQCsxjKxfiDJgaq6rqouT3JLkqM/eLC7n+zuK7r72u6+Nsn9SQ519/FdmRgA1syOse7up5PcnuTeJF9Kck93P1RVd1bVod0eEADW3b5lFnX3sSTHtt33rjOsffUzHwsA+AFXMAOA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOHEGgCGE2sAGE6sAWA4sQaA4cQaAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFguKViXVU3VNUjVXWiqu44zeNvq6qHq+rBqvpkVf306kcFgPW0Y6yr6rIkdyW5McnBJLdW1cFtyz6fZKO7fzHJPyX5s1UPCgDrapl31tcnOdHdj3b3U0nuTnLz1gXdfV93f2dxeH+Sq1Y7JgCsr2VifWWSx7Ycn1zcdya3JfnEMxkKAPihfat8sqp6Q5KNJK86w+OHkxxOkmuuuWaVLw0Al6xl3lk/nuTqLcdXLe77EVX12iTvTHKou793uifq7iPdvdHdG/v37z+feQFg7SwT6weSHKiq66rq8iS3JDm6dUFVvTzJ+7MZ6idWPyYArK8dY93dTye5Pcm9Sb6U5J7ufqiq7qyqQ4tlf57keUn+sar+raqOnuHpAIBztNTfrLv7WJJj2+5715bbr13xXADAgiuYAcBwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADCcWAPAcGINAMOJNQAMJ9YAMJxYA8BwYg0Aw4k1AAwn1gAwnFgDwHBiDQDDiTUADCfWADDcUrGuqhuq6pGqOlFVd5zm8R+rqo8uHv9sVV276kEBYF3tGOuquizJXUluTHIwya1VdXDbstuSfLu7fzbJXyX501UPCgDrapl31tcnOdHdj3b3U0nuTnLztjU3J/m7xe1/SvKaqqrVjQkA62uZWF+Z5LEtxycX9512TXc/neTJJD+1igEBYN3t28sXq6rDSQ4vDr9XVV/cy9dfQ1ck+caFHmIN2OfdZ493nz3efT93vt+4TKwfT3L1luOrFvedbs3JqtqX5AVJvrn9ibr7SJIjSVJVx7t743yGZjn2eG/Y591nj3efPd59VXX8fL93mY/BH0hyoKquq6rLk9yS5Oi2NUeT/O7i9m8l+Zfu7vMdCgD4oR3fWXf301V1e5J7k1yW5IPd/VBV3ZnkeHcfTfK3Sf6hqk4k+VY2gw4ArMBSf7Pu7mNJjm27711bbn83yW+f42sfOcf1nDt7vDfs8+6zx7vPHu++897j8mk1AMzmcqMAMNyux9qlSnffEnv8tqp6uKoerKpPVtVPX4g5L2Y77fGWda+rqq4qZ9Weh2X2uapev/h5fqiqPrzXM17slvh9cU1V3VdVn1/8zrjpQsx5MauqD1bVE2f658m16b2L/wYPVtUrdnzS7t61r2yekPYfSX4myeVJvpDk4LY1v5fkfYvbtyT56G7OdKl9LbnHv57kxxe332KPV7/Hi3XPT/LpJPcn2bjQc19sX0v+LB9I8vkkP7k4ftGFnvti+lpyj48kecvi9sEkX7nQc19sX0l+LckrknzxDI/flOQTSSrJK5N8dqfn3O131i5Vuvt23OPuvq+7v7M4vD+b/1ae5S3zc5wkf5LN6+J/dy+Hu4Qss89vTnJXd387Sbr7iT2e8WK3zB53kp9Y3H5Bkq/t4XyXhO7+dDb/ZdSZ3Jzk73vT/UleWFUvPttz7nasXap09y2zx1vdls3/o2N5O+7x4mOsq7v743s52CVmmZ/llyR5SVV9pqrur6ob9my6S8Mye/yeJG+oqpPZ/FdAb92b0dbKuf7e3tvLjXJhVdUbkmwkedWFnuVSUlXPSvKXSd54gUdZB/uy+VH4q7P5CdGnq+oXuvu/LuhUl5Zbk3you/+iqn4lm9fQeFl3/8+FHmyd7fY763O5VGnOdqlSzmiZPU5VvTbJO5Mc6u7v7dFsl4qd9vj5SV6W5FNV9ZVs/g3qqJPMztkyP8snkxzt7u9395eT/Hs2481yltnj25LckyTd/a9JnpPN64azOkv93t5qt2PtUqW7b8c9rqqXJ3l/NkPtb3zn7qx73N1PdvcV3X1td1+bzfMCDnX3eV8HeE0t8/viY9l8V52quiKbH4s/updDXuSW2eOvJnlNklTVz2cz1qf2dMpL39Ekv7M4K/yVSZ7s7q+f7Rt29WPwdqnSXbfkHv95kucl+cfFuXtf7e5DF2zoi8ySe8wztOQ+35vkN6vq4ST/neQd3e2TuCUtucdvT/KBqvrDbJ5s9kZvoM5NVX0km/9TecXib//vTvLsJOnu92XzXICbkpxI8p0kb9rxOf03AIDZXMEMAIYTawAYTqwBYDixBoDhxBoAhhNrABhOrAFgOLEGgOH+F8aRr82wJ3zGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show history\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# history.history['loss'].append(history2.history['loss'])\n",
    "# history.history['val_loss'].append(history2.history['val_loss'])\n",
    "# history.history['acc'].append(history2.history['acc'])\n",
    "# history.history['val_loss'].append(history2.history['val_loss'])\n",
    "\n",
    "# Loss Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves',fontsize=16)\n",
    " \n",
    "# Accuracy Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['acc'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_acc'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "# Predict for test data\n",
    "\n",
    "import helper\n",
    "\n",
    "test_files = helper.get_test_files()\n",
    "test_files = sorted(test_files, key=lambda s: (len(s), s))\n",
    "\n",
    "test_file_size = len(test_files)\n",
    "\n",
    "test_feature = []\n",
    "for i in range(test_file_size):\n",
    "    test_feature.append(readImage(test_files[i]))\n",
    "test_feature = np.asarray(test_feature)\n",
    "print(type(test_feature))\n",
    "test_label = model.predict(test_feature, batch_size=batch_size)\n",
    "print (len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Write out predict data to csv\n",
    "\n",
    "test_label_output = []\n",
    "for i in range(len(test_label)):\n",
    "    test_label_output.append([i + 1, test_label[i]])\n",
    "    \n",
    "print (len(test_label_output))\n",
    "test_label_output = np.array(test_label_output)\n",
    "np.savetxt(\"submission.csv\", test_label_output, fmt='%d,%f', delimiter=',', header=\"id,label\", comments=\"\")\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
